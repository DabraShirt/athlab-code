# GNN Autoencoder Training Configuration

# Default training configuration
default_training:
  # Training parameters
  num_epochs: 100
  batch_size: 16
  validation_split: 0.15
  test_split: 0.15
  shuffle_data: true
  random_seed: 42

  # Early stopping
  early_stopping:
    enabled: true
    patience: 15
    min_delta: 0.0001  # Use float instead of scientific notation
    restore_best_weights: true

  # Loss configuration
  loss_weights:
    reconstruction: 1.0
    anomaly: 0.1

  # Gradient clipping
  gradient_clipping:
    enabled: true
    max_grad_norm: 1.0

  # Checkpointing
  checkpoint:
    enabled: true
    save_best_only: false
    save_frequency: 10  # Save every N epochs
    monitor: "val_loss"
    mode: "min"

  # Optuna hyperparameter optimization
  optuna_params:
    n_trials: 50
    direction: "minimize"
    learning_rate:
      min: 0.00001
      max: 0.01
      log: true
    weight_decay:
      min: 0.000001
      max: 0.001
      log: true
    optimizer: ["Adam", "AdamW"]

# Optimizer configurations
optimizers:
  adam:
    type: "Adam"
    lr: 1e-3
    weight_decay: 1e-5
    betas: [0.9, 0.999]
    eps: 1e-8

  adamw:
    type: "AdamW"
    lr: 1e-3
    weight_decay: 1e-4
    betas: [0.9, 0.999]
    eps: 1e-8

  sgd:
    type: "SGD"
    lr: 1e-2
    momentum: 0.9
    weight_decay: 1e-5
    nesterov: true

# Learning rate scheduler configurations
schedulers:
  reduce_on_plateau:
    type: "ReduceLROnPlateau"
    mode: "min"
    factor: 0.5
    patience: 10
    min_lr: 1e-6
    verbose: true

  cosine_annealing:
    type: "CosineAnnealingLR"
    T_max: 50
    eta_min: 1e-6

  step_lr:
    type: "StepLR"
    step_size: 30
    gamma: 0.1

  exponential:
    type: "ExponentialLR"
    gamma: 0.95

# Data configuration
data_config:
  # Dataset parameters
  sequence_length: 1  # 1 for static, >1 for temporal
  overlap_ratio: 0.5
  normalize: true
  normalization_type: "standard"  # "standard", "minmax"
  remove_outliers: true
  outlier_threshold: 3.0

  # Synthetic anomaly generation
  synthetic_anomalies:
    enabled: true
    anomaly_ratio: 0.15
    anomaly_types: ["missing_points", "displaced_points", "noisy_points"]
    anomaly_strength: 2.0

  # Data augmentation
  augmentation:
    enabled: false
    noise_factor: 0.01
    rotation_range: 5  # degrees
    scale_range: 0.05

# Quick training configuration for testing
quick_training:
  num_epochs: 20
  batch_size: 32
  validation_split: 0.2
  test_split: 0.2
  early_stopping:
    enabled: true
    patience: 5
    min_delta: 0.0001
  loss_weights:
    reconstruction: 1.0
    anomaly: 0.05

# Intensive training configuration for production
intensive_training:
  num_epochs: 200
  batch_size: 8
  validation_split: 0.1
  test_split: 0.1
  early_stopping:
    enabled: true
    patience: 25
    min_delta: 0.00001
  loss_weights:
    reconstruction: 1.0
    anomaly: 0.2
  gradient_clipping:
    enabled: true
    max_grad_norm: 0.5

# Temporal sequence training configuration
temporal_training:
  num_epochs: 150
  batch_size: 8  # Smaller batch size for sequences
  validation_split: 0.15
  test_split: 0.15
  early_stopping:
    enabled: true
    patience: 15
    min_delta: 0.00001
  data_config:
    sequence_length: 10
    overlap_ratio: 0.3
  loss_weights:
    reconstruction: 1.0
    anomaly: 0.15
    temporal_consistency: 0.05
